{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e47af34",
   "metadata": {},
   "source": [
    "导入所需依赖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff43b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as c_transforms\n",
    "import mindspore.dataset.vision.c_transforms as c_vision\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.numpy import argmax\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9637b",
   "metadata": {},
   "source": [
    "设置动态图模式和使用设备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74db2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609e4b1",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ff8c5",
   "metadata": {},
   "source": [
    "定义超参及路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca70f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset/train\"\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08281836",
   "metadata": {},
   "source": [
    "定义创建数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3472a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dir, batch_size, repeat_num):\n",
    "    \"\"\"定义数据集\"\"\"\n",
    "    dataset = ds.ImageFolderDataset(dir, shuffle=True)\n",
    "\n",
    "    image_size = [224, 224]\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "    trans = [\n",
    "        c_vision.Decode(),\n",
    "        c_vision.Resize(image_size),\n",
    "        c_vision.Normalize(mean=mean, std=std),\n",
    "        c_vision.HWC2CHW()\n",
    "    ]\n",
    "\n",
    "    # 实现数据的map映射、批量处理和数据重复的操作\n",
    "    type_cast_op = c_transforms.TypeCast(ms.int32)\n",
    "    dataset = dataset.map(operations=trans, input_columns=\"image\")\n",
    "    dataset = dataset.map(operations=type_cast_op, input_columns=\"label\")\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.repeat(repeat_num)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8480f",
   "metadata": {},
   "source": [
    "构建ResNet50网络基础元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae0c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_variance_scaling_initializer(in_channel, out_channel, kernel_size):\n",
    "    fan_in = in_channel * kernel_size * kernel_size\n",
    "    scale = 1.0\n",
    "    scale /= max(1., fan_in)\n",
    "    stddev = (scale ** 0.5) / .87962566103423978\n",
    "    mu, sigma = 0, stddev\n",
    "    weight = truncnorm(-2, 2, loc=mu, scale=sigma).rvs(out_channel * in_channel * kernel_size * kernel_size)\n",
    "    weight = np.reshape(weight, (out_channel, in_channel, kernel_size, kernel_size))\n",
    "    return Tensor(weight, dtype=ms.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9ec9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weight_variable(shape, factor=0.01):\n",
    "    init_value = np.random.randn(*shape).astype(np.float32) * factor\n",
    "    return Tensor(init_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9d5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain(nonlinearity, param=None):\n",
    "    \"\"\"calculate_gain\"\"\"\n",
    "    linear_fns = ['linear', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d', 'conv_transpose2d', 'conv_transpose3d']\n",
    "    res = 0\n",
    "    if nonlinearity in linear_fns or nonlinearity == 'sigmoid':\n",
    "        res = 1\n",
    "    elif nonlinearity == 'tanh':\n",
    "        res = 5.0 / 3\n",
    "    elif nonlinearity == 'relu':\n",
    "        res = math.sqrt(2.0)\n",
    "    elif nonlinearity == 'leaky_relu':\n",
    "        if param is None:\n",
    "            neg_slope = 0.01\n",
    "        elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float):\n",
    "            neg_slope = param\n",
    "        else:\n",
    "            raise ValueError(\"neg_slope {} not a valid number\".format(param))\n",
    "        res = math.sqrt(2.0 / (1 + neg_slope ** 2))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported nonlinearity {}\".format(nonlinearity))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ca52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_fan_in_and_fan_out(tensor):\n",
    "    \"\"\"_calculate_fan_in_and_fan_out\"\"\"\n",
    "    dimensions = len(tensor)\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\")\n",
    "    if dimensions == 2:  # Linear\n",
    "        fan_in = tensor[1]\n",
    "        fan_out = tensor[0]\n",
    "    else:\n",
    "        num_input_fmaps = tensor[1]\n",
    "        num_output_fmaps = tensor[0]\n",
    "        receptive_field_size = 1\n",
    "        if dimensions > 2:\n",
    "            receptive_field_size = tensor[2] * tensor[3]\n",
    "        fan_in = num_input_fmaps * receptive_field_size\n",
    "        fan_out = num_output_fmaps * receptive_field_size\n",
    "    return fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfdbc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_correct_fan(tensor, mode):\n",
    "    mode = mode.lower()\n",
    "    valid_modes = ['fan_in', 'fan_out']\n",
    "    if mode not in valid_modes:\n",
    "        raise ValueError(\"Unsupported mode {}, please use one of {}\".format(mode, valid_modes))\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    return fan_in if mode == 'fan_in' else fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f25891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal(inputs_shape, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n",
    "    fan = _calculate_correct_fan(inputs_shape, mode)\n",
    "    gain = calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    return np.random.normal(0, std, size=inputs_shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c172e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_uniform(inputs_shape, a=0., mode='fan_in', nonlinearity='leaky_relu'):\n",
    "    fan = _calculate_correct_fan(inputs_shape, mode)\n",
    "    gain = calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    bound = math.sqrt(3.0) * std  # Calculate uniform bounds from standard deviation\n",
    "    return np.random.uniform(-bound, bound, size=inputs_shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f3226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv3x3(in_channel, out_channel, stride=1, use_se=False, res_base=False):\n",
    "    if use_se:\n",
    "        weight = conv_variance_scaling_initializer(in_channel, out_channel, kernel_size=3)\n",
    "    else:\n",
    "        weight_shape = (out_channel, in_channel, 3, 3)\n",
    "        weight = Tensor(kaiming_normal(weight_shape, mode=\"fan_out\", nonlinearity='relu'))\n",
    "    if res_base:\n",
    "        return nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride,\n",
    "                         padding=1, pad_mode='pad', weight_init=weight)\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride,\n",
    "                     padding=0, pad_mode='same', weight_init=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9fd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv1x1(in_channel, out_channel, stride=1, use_se=False, res_base=False):\n",
    "    if use_se:\n",
    "        weight = conv_variance_scaling_initializer(in_channel, out_channel, kernel_size=1)\n",
    "    else:\n",
    "        weight_shape = (out_channel, in_channel, 1, 1)\n",
    "        weight = Tensor(kaiming_normal(weight_shape, mode=\"fan_out\", nonlinearity='relu'))\n",
    "    if res_base:\n",
    "        return nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride,\n",
    "                         padding=0, pad_mode='pad', weight_init=weight)\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride,\n",
    "                     padding=0, pad_mode='same', weight_init=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5964fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv7x7(in_channel, out_channel, stride=1, use_se=False, res_base=False):\n",
    "    if use_se:\n",
    "        weight = conv_variance_scaling_initializer(in_channel, out_channel, kernel_size=7)\n",
    "    else:\n",
    "        weight_shape = (out_channel, in_channel, 7, 7)\n",
    "        weight = Tensor(kaiming_normal(weight_shape, mode=\"fan_out\", nonlinearity='relu'))\n",
    "    if res_base:\n",
    "        return nn.Conv2d(in_channel, out_channel,\n",
    "                         kernel_size=7, stride=stride, padding=3, pad_mode='pad', weight_init=weight)\n",
    "    return nn.Conv2d(in_channel, out_channel,\n",
    "                     kernel_size=7, stride=stride, padding=0, pad_mode='same', weight_init=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f26ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn(channel, res_base=False):\n",
    "    if res_base:\n",
    "        return nn.BatchNorm2d(channel, eps=1e-5, momentum=0.1,\n",
    "                              gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\n",
    "    return nn.BatchNorm2d(channel, eps=1e-4, momentum=0.9,\n",
    "                          gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\n",
    "\n",
    "\n",
    "def _bn_last(channel):\n",
    "    return nn.BatchNorm2d(channel, eps=1e-4, momentum=0.9,\n",
    "                          gamma_init=0, beta_init=0, moving_mean_init=0, moving_var_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a136cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fc(in_channel, out_channel, use_se=False):\n",
    "    if use_se:\n",
    "        weight = np.random.normal(loc=0, scale=0.01, size=out_channel * in_channel)\n",
    "        weight = Tensor(np.reshape(weight, (out_channel, in_channel)), dtype=ms.float32)\n",
    "    else:\n",
    "        weight_shape = (out_channel, in_channel)\n",
    "        weight = Tensor(kaiming_uniform(weight_shape, a=math.sqrt(5)))\n",
    "    return nn.Dense(in_channel, out_channel, has_bias=True, weight_init=weight, bias_init=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac610f",
   "metadata": {},
   "source": [
    "构建残差块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2890264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channel,\n",
    "                 out_channel,\n",
    "                 stride=1,\n",
    "                 use_se=False, se_block=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.use_se = use_se\n",
    "        self.se_block = se_block\n",
    "        channel = out_channel // self.expansion\n",
    "        self.conv1 = _conv1x1(in_channel, channel, stride=1, use_se=self.use_se)\n",
    "        self.bn1 = _bn(channel)\n",
    "        if self.use_se and self.stride != 1:\n",
    "            self.e2 = nn.SequentialCell([_conv3x3(channel, channel, stride=1, use_se=True), _bn(channel),\n",
    "                                         nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='same')])\n",
    "        else:\n",
    "            self.conv2 = _conv3x3(channel, channel, stride=stride, use_se=self.use_se)\n",
    "            self.bn2 = _bn(channel)\n",
    "\n",
    "        self.conv3 = _conv1x1(channel, out_channel, stride=1, use_se=self.use_se)\n",
    "        self.bn3 = _bn(out_channel)\n",
    "        if self.se_block:\n",
    "            self.se_global_pool = P.ReduceMean(keep_dims=False)\n",
    "            self.se_dense_0 = _fc(out_channel, int(out_channel / 4), use_se=self.use_se)\n",
    "            self.se_dense_1 = _fc(int(out_channel / 4), out_channel, use_se=self.use_se)\n",
    "            self.se_sigmoid = nn.Sigmoid()\n",
    "            self.se_mul = P.Mul()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.down_sample = False\n",
    "\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.down_sample = True\n",
    "        self.down_sample_layer = None\n",
    "\n",
    "        if self.down_sample:\n",
    "            if self.use_se:\n",
    "                if stride == 1:\n",
    "                    self.down_sample_layer = nn.SequentialCell([_conv1x1(in_channel, out_channel,\n",
    "                                                                         stride, use_se=self.use_se), _bn(out_channel)])\n",
    "                else:\n",
    "                    self.down_sample_layer = nn.SequentialCell([nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='same'),\n",
    "                                                                _conv1x1(in_channel, out_channel, 1,\n",
    "                                                                         use_se=self.use_se), _bn(out_channel)])\n",
    "            else:\n",
    "                self.down_sample_layer = nn.SequentialCell([_conv1x1(in_channel, out_channel, stride,\n",
    "                                                                     use_se=self.use_se), _bn(out_channel)])\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.use_se and self.stride != 1:\n",
    "            out = self.e2(out)\n",
    "        else:\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "            out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.se_block:\n",
    "            out_se = out\n",
    "            out = self.se_global_pool(out, (2, 3))\n",
    "            out = self.se_dense_0(out)\n",
    "            out = self.relu(out)\n",
    "            out = self.se_dense_1(out)\n",
    "            out = self.se_sigmoid(out)\n",
    "            out = F.reshape(out, F.shape(out) + (1, 1))\n",
    "            out = self.se_mul(out, out_se)\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample_layer(identity)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea86368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockBase(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 in_channel,\n",
    "                 out_channel,\n",
    "                 stride=1,\n",
    "                 use_se=False,\n",
    "                 se_block=False,\n",
    "                 res_base=True):\n",
    "        super(ResidualBlockBase, self).__init__()\n",
    "        self.res_base = res_base\n",
    "        self.conv1 = _conv3x3(in_channel, out_channel, stride=stride, res_base=self.res_base)\n",
    "        self.bn1d = _bn(out_channel)\n",
    "        self.conv2 = _conv3x3(out_channel, out_channel, stride=1, res_base=self.res_base)\n",
    "        self.bn2d = _bn(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.down_sample = True\n",
    "\n",
    "        self.down_sample_layer = None\n",
    "        if self.down_sample:\n",
    "            self.down_sample_layer = nn.SequentialCell([_conv1x1(in_channel, out_channel, stride,\n",
    "                                                                 use_se=use_se, res_base=self.res_base),\n",
    "                                                        _bn(out_channel, res_base)])\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1d(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2d(out)\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample_layer(identity)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd2d5f",
   "metadata": {},
   "source": [
    "构建ResNet50架构:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96d0a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layer_nums,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 strides,\n",
    "                 num_classes,\n",
    "                 use_se=False,\n",
    "                 res_base=False):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        if not len(layer_nums) == len(in_channels) == len(out_channels) == 4:\n",
    "            raise ValueError(\"the length of layer_num, in_channels, out_channels list must be 4!\")\n",
    "        self.use_se = use_se\n",
    "        self.res_base = res_base\n",
    "        self.se_block = False\n",
    "        if self.use_se:\n",
    "            self.se_block = True\n",
    "\n",
    "        if self.use_se:\n",
    "            self.conv1_0 = _conv3x3(3, 32, stride=2, use_se=self.use_se)\n",
    "            self.bn1_0 = _bn(32)\n",
    "            self.conv1_1 = _conv3x3(32, 32, stride=1, use_se=self.use_se)\n",
    "            self.bn1_1 = _bn(32)\n",
    "            self.conv1_2 = _conv3x3(32, 64, stride=1, use_se=self.use_se)\n",
    "        else:\n",
    "            self.conv1 = _conv7x7(3, 64, stride=2, res_base=self.res_base)\n",
    "        self.bn1 = _bn(64, self.res_base)\n",
    "        self.relu = P.ReLU()\n",
    "\n",
    "        if self.res_base:\n",
    "            self.pad = nn.Pad(paddings=((0, 0), (0, 0), (1, 1), (1, 1)))\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode=\"valid\")\n",
    "        else:\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode=\"same\")\n",
    "\n",
    "        self.layer1 = self._make_layer(block,\n",
    "                                       layer_nums[0],\n",
    "                                       in_channel=in_channels[0],\n",
    "                                       out_channel=out_channels[0],\n",
    "                                       stride=strides[0],\n",
    "                                       use_se=self.use_se)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       layer_nums[1],\n",
    "                                       in_channel=in_channels[1],\n",
    "                                       out_channel=out_channels[1],\n",
    "                                       stride=strides[1],\n",
    "                                       use_se=self.use_se)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       layer_nums[2],\n",
    "                                       in_channel=in_channels[2],\n",
    "                                       out_channel=out_channels[2],\n",
    "                                       stride=strides[2],\n",
    "                                       use_se=self.use_se,\n",
    "                                       se_block=self.se_block)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       layer_nums[3],\n",
    "                                       in_channel=in_channels[3],\n",
    "                                       out_channel=out_channels[3],\n",
    "                                       stride=strides[3],\n",
    "                                       use_se=self.use_se,\n",
    "                                       se_block=self.se_block)\n",
    "\n",
    "        self.mean = P.ReduceMean(keep_dims=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.end_point = _fc(out_channels[3], num_classes, use_se=self.use_se)\n",
    "\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride, use_se=False, se_block=False):\n",
    "        layers = []\n",
    "\n",
    "        resnet_block = block(in_channel, out_channel, stride=stride, use_se=use_se)\n",
    "        layers.append(resnet_block)\n",
    "        if se_block:\n",
    "            for _ in range(1, layer_num - 1):\n",
    "                resnet_block = block(out_channel, out_channel, stride=1, use_se=use_se)\n",
    "                layers.append(resnet_block)\n",
    "            resnet_block = block(out_channel, out_channel, stride=1, use_se=use_se, se_block=se_block)\n",
    "            layers.append(resnet_block)\n",
    "        else:\n",
    "            for _ in range(1, layer_num):\n",
    "                resnet_block = block(out_channel, out_channel, stride=1, use_se=use_se)\n",
    "                layers.append(resnet_block)\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        if self.use_se:\n",
    "            x = self.conv1_0(x)\n",
    "            x = self.bn1_0(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv1_1(x)\n",
    "            x = self.bn1_1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv1_2(x)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.res_base:\n",
    "            x = self.pad(x)\n",
    "        c1 = self.maxpool(x)\n",
    "\n",
    "        c2 = self.layer1(c1)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        out = self.mean(c5, (2, 3))\n",
    "        out = self.flatten(out)\n",
    "        out = self.end_point(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7f083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T07:32:36.318852Z",
     "start_time": "2022-12-31T07:32:36.302340Z"
    }
   },
   "source": [
    "初始化训练集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d240c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_dir, batch_size=50, repeat_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269901d7",
   "metadata": {},
   "source": [
    "初始化网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffc48471",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(ResidualBlock,\n",
    "                  [3, 4, 6, 3],\n",
    "                  [64, 256, 512, 1024],\n",
    "                  [256, 512, 1024, 2048],\n",
    "                  [1, 2, 2, 2],\n",
    "                  10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4e226",
   "metadata": {},
   "source": [
    "定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64e9dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44993e9e",
   "metadata": {},
   "source": [
    "定义优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da5f2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.Momentum(params=net.trainable_params(),\n",
    "                    learning_rate=lr,\n",
    "                    momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dabd08",
   "metadata": {},
   "source": [
    "初始化网络模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "762abb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ms.Model(network=net, loss_fn=loss, optimizer=optim, metrics={\"Accuracy\": nn.Accuracy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2ffad",
   "metadata": {},
   "source": [
    "模型训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12647726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time: 77300.139 ms, per step time: 858.890 ms, avg loss: 1.984\n",
      "Epoch:[  1/ 20], step:[   90/   90], loss:[1.740/1.740], time:6317.800 ms, lr:0.01000\n",
      "Epoch time: 6325.423 ms, per step time: 70.282 ms, avg loss: 1.740\n",
      "Epoch time: 6313.465 ms, per step time: 70.150 ms, avg loss: 1.802\n",
      "Epoch:[  3/ 20], step:[   90/   90], loss:[1.628/1.628], time:6312.927 ms, lr:0.01000\n",
      "Epoch time: 6318.117 ms, per step time: 70.201 ms, avg loss: 1.628\n",
      "Epoch time: 6324.910 ms, per step time: 70.277 ms, avg loss: 1.689\n",
      "Epoch:[  5/ 20], step:[   90/   90], loss:[1.633/1.633], time:6307.847 ms, lr:0.01000\n",
      "Epoch time: 6312.997 ms, per step time: 70.144 ms, avg loss: 1.633\n",
      "Epoch time: 6327.607 ms, per step time: 70.307 ms, avg loss: 1.427\n",
      "Epoch:[  7/ 20], step:[   90/   90], loss:[1.466/1.466], time:6313.949 ms, lr:0.01000\n",
      "Epoch time: 6320.307 ms, per step time: 70.226 ms, avg loss: 1.466\n",
      "Epoch time: 6313.997 ms, per step time: 70.156 ms, avg loss: 1.249\n",
      "Epoch:[  9/ 20], step:[   90/   90], loss:[1.209/1.209], time:6312.789 ms, lr:0.01000\n",
      "Epoch time: 6318.296 ms, per step time: 70.203 ms, avg loss: 1.209\n",
      "Epoch time: 6343.651 ms, per step time: 70.485 ms, avg loss: 0.910\n",
      "Epoch:[ 11/ 20], step:[   90/   90], loss:[1.149/1.149], time:6315.793 ms, lr:0.01000\n",
      "Epoch time: 6324.347 ms, per step time: 70.271 ms, avg loss: 1.149\n",
      "Epoch time: 6331.513 ms, per step time: 70.350 ms, avg loss: 1.167\n",
      "Epoch:[ 13/ 20], step:[   90/   90], loss:[1.250/1.250], time:6310.287 ms, lr:0.01000\n",
      "Epoch time: 6315.155 ms, per step time: 70.168 ms, avg loss: 1.250\n",
      "Epoch time: 6317.418 ms, per step time: 70.194 ms, avg loss: 1.110\n",
      "Epoch:[ 15/ 20], step:[   90/   90], loss:[1.082/1.082], time:6345.617 ms, lr:0.01000\n",
      "Epoch time: 6353.501 ms, per step time: 70.594 ms, avg loss: 1.082\n",
      "Epoch time: 6328.100 ms, per step time: 70.312 ms, avg loss: 0.682\n",
      "Epoch:[ 17/ 20], step:[   90/   90], loss:[1.023/1.023], time:6308.991 ms, lr:0.01000\n",
      "Epoch time: 6314.320 ms, per step time: 70.159 ms, avg loss: 1.023\n",
      "Epoch time: 6317.613 ms, per step time: 70.196 ms, avg loss: 0.667\n",
      "Epoch:[ 19/ 20], step:[   90/   90], loss:[0.555/0.555], time:6357.090 ms, lr:0.01000\n",
      "Epoch time: 6370.766 ms, per step time: 70.786 ms, avg loss: 0.555\n"
     ]
    }
   ],
   "source": [
    "model.train(train_dataset=train_dataset, epoch=epochs,\n",
    "            callbacks=[LossMonitor(lr_init=lr, per_print_times=100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165fca4",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e10bd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.save_checkpoint(net, \"resnet50.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37043178",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd70cc",
   "metadata": {},
   "source": [
    "处理测试图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8301239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "    image = cv2.resize(image, (224, 224), cv2.INTER_LINEAR)\n",
    "    image = image / 1.0\n",
    "    image = (image[:, :] - mean) / std\n",
    "    image = image[:, :, ::-1].transpose((2, 0, 1))  # HWC-->CHW\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1954163",
   "metadata": {},
   "source": [
    "迭代处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9be198e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_deal(data_path):\n",
    "    image = cv2.imread(data_path)\n",
    "    norm_img = normalize(image)\n",
    "    images = [norm_img]\n",
    "    images = ms.Tensor(images, ms.float32)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671ccc7",
   "metadata": {},
   "source": [
    "推理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b7d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(ckpt_path, data_path):\n",
    "    image = pre_deal(data_path)\n",
    "\n",
    "    net = ResNet(ResidualBlock,\n",
    "                  [3, 4, 6, 3],\n",
    "                  [64, 256, 512, 1024],\n",
    "                  [256, 512, 1024, 2048],\n",
    "                  [1, 2, 2, 2],\n",
    "                  10)\n",
    "    param_dict = ms.load_checkpoint(ckpt_path)\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    model = ms.Model(net, loss, metrics={\"Accuracy\": nn.Accuracy()})\n",
    "\n",
    "    output = model.predict(image)\n",
    "    pred = argmax(output, axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e868de6",
   "metadata": {},
   "source": [
    "保存推理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40d659d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'resnet50.ckpt'\n",
    "\n",
    "# 存储结果\n",
    "pred_list = []\n",
    "\n",
    "# 提取图片顺序\n",
    "key = lambda x: int(x[4:-4])\n",
    "\n",
    "def info(test_dir):\n",
    "    \"\"\"推理图片\"\"\"\n",
    "    path_list = os.listdir(os.path.join(test_dir))\n",
    "    path_list.sort(key=key)\n",
    "    for path in path_list:\n",
    "        path = os.path.join(test_dir) + '/' + path\n",
    "        print(path)\n",
    "        result = infer(ckpt_path, path)\n",
    "        print(\"The class is\", result[0])\n",
    "        result = str(result[0])\n",
    "        result = result + \"\\n\"\n",
    "        pred_list.append(result)\n",
    "\n",
    "# 粗糙地手动分批\n",
    "test_dir1 = \"dataset/test/part1\"\n",
    "test_dir2 = \"dataset/test/part2\"\n",
    "test_dir3 = \"dataset/test/part3\"\n",
    "test_dir4 = \"dataset/test/part4\"\n",
    "test_dir5 = \"dataset/test/part5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3d27b0-05fe-4632-b2ac-76e5f7b8ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test/part1/img_0.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_1.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_2.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_3.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_4.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_5.jpg\n",
      "The class is 8\n",
      "dataset/test/part1/img_6.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_7.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_8.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_9.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_10.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_11.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_12.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_13.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_14.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_15.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_16.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_17.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_18.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_19.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_20.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_21.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_22.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_23.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_24.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_25.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_26.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_27.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_28.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_29.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_30.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_31.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_32.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_33.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_34.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_35.jpg\n",
      "The class is 8\n",
      "dataset/test/part1/img_36.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_37.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_38.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_39.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_40.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_41.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_42.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_43.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_44.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_45.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_46.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_47.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_48.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_49.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_50.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_51.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_52.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_53.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_54.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_55.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_56.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_57.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_58.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_59.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_60.jpg\n",
      "The class is 8\n",
      "dataset/test/part1/img_61.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_62.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_63.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_64.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_65.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_66.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_67.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_68.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_69.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_70.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_71.jpg\n",
      "The class is 3\n",
      "dataset/test/part1/img_72.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_73.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_74.jpg\n",
      "The class is 6\n",
      "dataset/test/part1/img_75.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_76.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_77.jpg\n",
      "The class is 8\n",
      "dataset/test/part1/img_78.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_79.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_80.jpg\n",
      "The class is 6\n",
      "dataset/test/part1/img_81.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_82.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_83.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_84.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_85.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_86.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_87.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_88.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_89.jpg\n",
      "The class is 0\n",
      "dataset/test/part1/img_90.jpg\n",
      "The class is 1\n",
      "dataset/test/part1/img_91.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_92.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_93.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_94.jpg\n",
      "The class is 4\n",
      "dataset/test/part1/img_95.jpg\n",
      "The class is 2\n",
      "dataset/test/part1/img_96.jpg\n",
      "The class is 5\n",
      "dataset/test/part1/img_97.jpg\n",
      "The class is 9\n",
      "dataset/test/part1/img_98.jpg\n",
      "The class is 7\n",
      "dataset/test/part1/img_99.jpg\n",
      "The class is 0\n"
     ]
    }
   ],
   "source": [
    "info(test_dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "717d79fa-948d-476f-a0f5-5ff57dadaf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test/part2/img_100.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_101.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_102.jpg\n",
      "The class is 7\n",
      "dataset/test/part2/img_103.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_104.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_105.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_106.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_107.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_108.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_109.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_110.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_111.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_112.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_113.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_114.jpg\n",
      "The class is 7\n",
      "dataset/test/part2/img_115.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_116.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_117.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_118.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_119.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_120.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_121.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_122.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_123.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_124.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_125.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_126.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_127.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_128.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_129.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_130.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_131.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_132.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_133.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_134.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_135.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_136.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_137.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_138.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_139.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_140.jpg\n",
      "The class is 7\n",
      "dataset/test/part2/img_141.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_142.jpg\n",
      "The class is 8\n",
      "dataset/test/part2/img_143.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_144.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_145.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_146.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_147.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_148.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_149.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_150.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_151.jpg\n",
      "The class is 7\n",
      "dataset/test/part2/img_152.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_153.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_154.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_155.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_156.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_157.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_158.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_159.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_160.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_161.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_162.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_163.jpg\n",
      "The class is 7\n",
      "dataset/test/part2/img_164.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_165.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_166.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_167.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_168.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_169.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_170.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_171.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_172.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_173.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_174.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_175.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_176.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_177.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_178.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_179.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_180.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_181.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_182.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_183.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_184.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_185.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_186.jpg\n",
      "The class is 2\n",
      "dataset/test/part2/img_187.jpg\n",
      "The class is 3\n",
      "dataset/test/part2/img_188.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_189.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_190.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_191.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_192.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_193.jpg\n",
      "The class is 0\n",
      "dataset/test/part2/img_194.jpg\n",
      "The class is 9\n",
      "dataset/test/part2/img_195.jpg\n",
      "The class is 1\n",
      "dataset/test/part2/img_196.jpg\n",
      "The class is 6\n",
      "dataset/test/part2/img_197.jpg\n",
      "The class is 4\n",
      "dataset/test/part2/img_198.jpg\n",
      "The class is 5\n",
      "dataset/test/part2/img_199.jpg\n",
      "The class is 9\n"
     ]
    }
   ],
   "source": [
    "info(test_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e25c208-a210-477e-800b-493027d62e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test/part3/img_200.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_201.jpg\n",
      "The class is 7\n",
      "dataset/test/part3/img_202.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_203.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_204.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_205.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_206.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_207.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_208.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_209.jpg\n",
      "The class is 7\n",
      "dataset/test/part3/img_210.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_211.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_212.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_213.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_214.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_215.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_216.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_217.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_218.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_219.jpg\n",
      "The class is 7\n",
      "dataset/test/part3/img_220.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_221.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_222.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_223.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_224.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_225.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_226.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_227.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_228.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_229.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_230.jpg\n",
      "The class is 7\n",
      "dataset/test/part3/img_231.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_232.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_233.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_234.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_235.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_236.jpg\n",
      "The class is 8\n",
      "dataset/test/part3/img_237.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_238.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_239.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_240.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_241.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_242.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_243.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_244.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_245.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_246.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_247.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_248.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_249.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_250.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_251.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_252.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_253.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_254.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_255.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_256.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_257.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_258.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_259.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_260.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_261.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_262.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_263.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_264.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_265.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_266.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_267.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_268.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_269.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_270.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_271.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_272.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_273.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_274.jpg\n",
      "The class is 8\n",
      "dataset/test/part3/img_275.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_276.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_277.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_278.jpg\n",
      "The class is 7\n",
      "dataset/test/part3/img_279.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_280.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_281.jpg\n",
      "The class is 6\n",
      "dataset/test/part3/img_282.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_283.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_284.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_285.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_286.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_287.jpg\n",
      "The class is 3\n",
      "dataset/test/part3/img_288.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_289.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_290.jpg\n",
      "The class is 0\n",
      "dataset/test/part3/img_291.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_292.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_293.jpg\n",
      "The class is 8\n",
      "dataset/test/part3/img_294.jpg\n",
      "The class is 2\n",
      "dataset/test/part3/img_295.jpg\n",
      "The class is 5\n",
      "dataset/test/part3/img_296.jpg\n",
      "The class is 4\n",
      "dataset/test/part3/img_297.jpg\n",
      "The class is 1\n",
      "dataset/test/part3/img_298.jpg\n",
      "The class is 9\n",
      "dataset/test/part3/img_299.jpg\n",
      "The class is 6\n"
     ]
    }
   ],
   "source": [
    "info(test_dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c1f4e69-6b6e-445a-b9f7-8a8841b12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"pred.txt\", \"a\")\n",
    "file.writelines(pred_list)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1eb0b29-cb7a-43eb-b685-fecb0400b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a91bb5b-731f-4468-822b-a762042428c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test/part4/img_300.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_301.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_302.jpg\n",
      "The class is 8\n",
      "dataset/test/part4/img_303.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_304.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_305.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_306.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_307.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_308.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_309.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_310.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_311.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_312.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_313.jpg\n",
      "The class is 8\n",
      "dataset/test/part4/img_314.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_315.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_316.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_317.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_318.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_319.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_320.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_321.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_322.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_323.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_324.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_325.jpg\n",
      "The class is 7\n",
      "dataset/test/part4/img_326.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_327.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_328.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_329.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_330.jpg\n",
      "The class is 7\n",
      "dataset/test/part4/img_331.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_332.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_333.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_334.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_335.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_336.jpg\n",
      "The class is 8\n",
      "dataset/test/part4/img_337.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_338.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_339.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_340.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_341.jpg\n",
      "The class is 8\n",
      "dataset/test/part4/img_342.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_343.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_344.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_345.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_346.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_347.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_348.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_349.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_350.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_351.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_352.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_353.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_354.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_355.jpg\n",
      "The class is 7\n",
      "dataset/test/part4/img_356.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_357.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_358.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_359.jpg\n",
      "The class is 6\n",
      "dataset/test/part4/img_360.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_361.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_362.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_363.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_364.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_365.jpg\n",
      "The class is 6\n",
      "dataset/test/part4/img_366.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_367.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_368.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_369.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_370.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_371.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_372.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_373.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_374.jpg\n",
      "The class is 3\n",
      "dataset/test/part4/img_375.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_376.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_377.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_378.jpg\n",
      "The class is 0\n",
      "dataset/test/part4/img_379.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_380.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_381.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_382.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_383.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_384.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_385.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_386.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_387.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_388.jpg\n",
      "The class is 7\n",
      "dataset/test/part4/img_389.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_390.jpg\n",
      "The class is 2\n",
      "dataset/test/part4/img_391.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_392.jpg\n",
      "The class is 6\n",
      "dataset/test/part4/img_393.jpg\n",
      "The class is 9\n",
      "dataset/test/part4/img_394.jpg\n",
      "The class is 4\n",
      "dataset/test/part4/img_395.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_396.jpg\n",
      "The class is 5\n",
      "dataset/test/part4/img_397.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_398.jpg\n",
      "The class is 1\n",
      "dataset/test/part4/img_399.jpg\n",
      "The class is 5\n"
     ]
    }
   ],
   "source": [
    "info(test_dir4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bdfc680-406c-4834-aee3-4156a248e8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test/part5/img_400.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_401.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_402.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_403.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_404.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_405.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_406.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_407.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_408.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_409.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_410.jpg\n",
      "The class is 7\n",
      "dataset/test/part5/img_411.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_412.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_413.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_414.jpg\n",
      "The class is 7\n",
      "dataset/test/part5/img_415.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_416.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_417.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_418.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_419.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_420.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_421.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_422.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_423.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_424.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_425.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_426.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_427.jpg\n",
      "The class is 7\n",
      "dataset/test/part5/img_428.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_429.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_430.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_431.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_432.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_433.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_434.jpg\n",
      "The class is 6\n",
      "dataset/test/part5/img_435.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_436.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_437.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_438.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_439.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_440.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_441.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_442.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_443.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_444.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_445.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_446.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_447.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_448.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_449.jpg\n",
      "The class is 7\n",
      "dataset/test/part5/img_450.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_451.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_452.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_453.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_454.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_455.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_456.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_457.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_458.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_459.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_460.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_461.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_462.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_463.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_464.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_465.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_466.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_467.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_468.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_469.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_470.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_471.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_472.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_473.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_474.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_475.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_476.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_477.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_478.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_479.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_480.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_481.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_482.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_483.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_484.jpg\n",
      "The class is 5\n",
      "dataset/test/part5/img_485.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_486.jpg\n",
      "The class is 0\n",
      "dataset/test/part5/img_487.jpg\n",
      "The class is 3\n",
      "dataset/test/part5/img_488.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_489.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_490.jpg\n",
      "The class is 2\n",
      "dataset/test/part5/img_491.jpg\n",
      "The class is 9\n",
      "dataset/test/part5/img_492.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_493.jpg\n",
      "The class is 8\n",
      "dataset/test/part5/img_494.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_495.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_496.jpg\n",
      "The class is 1\n",
      "dataset/test/part5/img_497.jpg\n",
      "The class is 6\n",
      "dataset/test/part5/img_498.jpg\n",
      "The class is 4\n",
      "dataset/test/part5/img_499.jpg\n",
      "The class is 9\n"
     ]
    }
   ],
   "source": [
    "info(test_dir5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e646a95a-a865-402c-8a4c-9eb91d7f46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"pred.txt\", \"a\")\n",
    "file.writelines(pred_list)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
